---
title: "3. Objects in kubernetes"
description: ""
date: "2026-02-05"
---



## Objects in kubernetes 

Kubernetes objects are persistent entities in the Kubernetes system. Kubernetes uses these entities to represent the state of your cluster. Specifically, they can describe:

- What containerized applications are running (and on which nodes)
- The resources available to those applications
- The policies around how those applications behave, such as restart policies, upgrades, and fault-tolerance

A Kubernetes object is a "record of intent"--once you create the object, the Kubernetes system will constantly work to ensure that the object exists. By creating an object, you're effectively telling the Kubernetes system what you want your cluster's workload to look like; this is your cluster's _desired state_.

To work with kubernetes objects whether to create, modify, or delete them—you'll need to use the Kubernetes API. When you use the `kubectl` command-line interface, for example, the CLI makes the necessary Kubernetes API calls for you.


### Object spec and status

Almost every Kubernetes object includes two nested object fields that govern the object's configuration: the object _`spec`_ and the object _`status`_. For objects that have a `spec`, you have to set this when you create the object, providing a description of the characteristics you want the resource to have: its desired state.

Almost every Kubernetes object includes two nested object fields that govern the object's configuration: the object _`spec`_ and the object _`status`_. For objects that have a `spec`, you have to set this when you create the object, providing a description of the characteristics you want the resource to have: its desired state.

For example in Kubernetes, a Deployment is an object that can represent an application running on your cluster. When you create the Deployment, you might set the Deployment `spec` to specify that you want three replicas of the application to be running.

When you create an object in Kubernetes, you must provide the object spec that describes its desired state, as well as some basic information about the object (such as a name). When you use the Kubernetes API to create the object (either directly or via `kubectl`), that API request must include that information as JSON in the request body. Most often, you provide the information to `kubectl` in a file known as a _manifest_. By convention, manifests are YAML (you could also use JSON format). Tools such as `kubectl` convert the information from a manifest into JSON or another supported serialization format when making the API request over HTTP.

Example of manifest- 

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2 # tells deployment to run 2 pods matching the template
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

  
One way to create a Deployment using a manifest file like the one above is to use the `kubectl apply` command in the `kubectl` command-line interface, passing the `.yaml` file as an argument.

In the manifest (YAML or JSON file) for the Kubernetes object you want to create, you'll need to set values for the following fields:

- api-version - Which version of the Kubernetes API you're using to create this object
- kind - What kind of object you want to create
- `metadata` - Data that helps uniquely identify the object, including a `name` string, `UID`, and optional `namespace`
- `spec` - What state you desire for the object

The precise format of the object `spec` is different for every Kubernetes object, and contains nested fields specific to that object.

In Kubernetes, the `containers` section is the heart of your Pod. It defines the actual application workloads you want to run. Because a Pod is a "logical host," it can contain one or multiple containers that share the same network and storage.

## Objects types

### Pods

_Pods_ are the smallest deployable units of computing that you can create and manage in Kubernetes.A _Pod_ (as in a pod of whales or pea pod) is a group of one or more containers, with shared storage and network resources, and a specification for how to run the containers. A Pod's contents are always co-located and co-scheduled, and run in a shared context.

Note before running pods on the nodes we must install the container runtime on each worker nodes. The shared context of a Pod is a set of Linux namespaces, cgroups, and potentially other facets of isolation - the same things that isolate a container. Within a Pod's context, the individual applications may have further sub-isolations applied. A Pod is similar to a set of containers with shared namespaces and shared filesystem volumes. We can run mulitple containers in a pod or one pod one application can also be followed. 

Sample yaml - 

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80
```

Pods are generally not created directly and are created using workload resources such as deployment or job. 

Pod templates are the controllers for the workload resources that create Pods from `pod template`
and manage those Pods on your behalf.

PodTemplates are specifications for creating Pods, and are included in workload resources such as Deployments and jobs. Each controller for a workload resource uses the `PodTemplate` inside the workload object to make actual Pods. The `PodTemplate` is part of the desired state of whatever workload resource you used to run your app.

When you create a Pod, you can include environment variables in the Pod template for the containers that run in the Pod.

When you create a Pod, you can set environment variables for the containers that run in the Pod. To set environment variables, include the `env` or `envFrom` field in the configuration file.
The `env` and `envFrom` fields have different effects.

`env`
allows you to set environment variables for a container, specifying a value directly for each variable that you name.

`envFrom`
allows you to set environment variables for a container by referencing either a ConfigMap or a Secret. When you use `envFrom`, all the key-value pairs in the referenced ConfigMap or Secret are set as environment variables for the container. You can also specify a common prefix string.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: envar-demo
  labels:
    purpose: demonstrate-envars
spec:
  containers:
  - name: envar-demo-container
    image: gcr.io/google-samples/hello-app:2.0
    env:
    - name: DEMO_GREETING
      value: "Hello from the environment"
    - name: DEMO_FAREWELL
      value: "Such a sweet sorrow"

```

The sample below is a manifest for a simple Job with a `template` that starts one container. The container in that Pod prints a message then pauses.

```bash
apiVersion: batch/v1
kind: Job
metadata:
  name: hello
spec:
  template:
    # This is the pod template
    spec:
      containers:
      - name: hello
        image: busybox:1.28
        command: ['sh', '-c', 'echo "Hello, Kubernetes!" && sleep 3600']
      restartPolicy: OnFailure
    # The pod template ends here
```

Modifying the pod template or switching to a new pod template has no direct effect on the Pods that already exist. 

A Pod can specify a set of shared storage [volumes](https://kubernetes.io/docs/concepts/storage/volumes/). All containers in the Pod can access the shared volumes, allowing those containers to share data. Volumes also allow persistent data in a Pod to survive in case one of the containers within needs to be restarted.

Each Pod is assigned a unique IP address for each address family. Every container in a Pod shares the network namespace, including the IP address and network ports. Inside a Pod (and **only** then), the containers that belong to the Pod can communicate with one another using `localhost`. When containers in a Pod communicate with entities _outside the Pod_, they must coordinate how they use the shared network resources (such as ports). Within a Pod, containers share an IP address and port space, and can find each other via `localhost`.

## Workloads 

A workload is an application running on Kubernetes. Whether your workload is a single component or several that work together, on Kubernetes you run it inside a set of pods.
However, to make life considerably easier, you don't need to manage each Pod directly. Instead, you can use _workload resources_ that manage a set of pods on your behalf.These resources configure controllers that make sure the right number of the right kind of pod are running, to match the state you specified.

Kubernetes has several built in workloads - 
### Deployment and replicaset

A ReplicaSet's purpose is to maintain a stable set of replica Pods running at any given time. Usually, you define a Deployment and let that Deployment manage ReplicaSets automatically.
A ReplicaSet's purpose is to maintain a stable set of replica Pods running at any given time. As such, it is often used to guarantee the availability of a specified number of identical Pods.

A Deployment manages a set of Pods to run an application workload, usually one that doesn't maintain state. These resources configure controllers that make sure the right number of the right kind of pod are running, to match the state you specified.  You describe a _desired state_ in a Deployment, and the Deployment Controller changes the actual state to the desired state at a controlled rate.

Example 

```bash
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

A Deployment named `nginx-deployment` is created, indicated by the `.metadata.name` field. This name will become the basis for the ReplicaSets and Pods which are created later. The Deployment creates a ReplicaSet that creates three replicated Pods, indicated by the `.spec.replicas` field.

The `.spec.selector.matchLabels` field is a map of `{key,value}` pairs. A single `{key,value}` in the `matchLabels` map is equivalent to an element of `matchExpressions`, whose `key` field is "key", the `operator` is "In", and the `values` array contains only "value". All of the requirements, from both `matchLabels` and `matchExpressions`, must be satisfied in order to match.

#### Writing deployment spec

When the control plane creates new Pods for a Deployment, the `.metadata.name` of the Deployment is part of the basis for naming those Pods. Deployment needs `.spec` section. 

```bash
template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

The `.spec.template` and `.spec.selector` are the only required fields of the `.spec`.

The `.spec.template` is a Pod template. It has exactly the same schema as a Pod, except it is nested and does not have an `apiVersion` or `kind`. In addition to required fields for a Pod, a Pod template in a Deployment must specify appropriate labels and an appropriate restart policy.

```bash
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
```

`.spec.replicas` is an optional field that specifies the number of desired Pods. It defaults to 1. If horizontal autoscaler is being used don't use this field. 

`.spec.selector` is a required field that specifies a label selector for pods. 
`.spec.selector` must match `.spec.template.metadata.labels`, or it will be rejected by the API. 

#### Config files

These files allow you to decouple configuration and sensitive data (passwords) from your application code.

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  LOG_LEVEL: "DEBUG"
  DATABASE_URL: "db.example.com"
```

Secret

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
type: Opaque
data:
  password: bXktcGFzc3dvcmQ=  # "my-password" encoded in Base64
```

To get configuration data (from a **ConfigMap** or **Secret**) into a **Pod**, you don't "pull" it manually via code. Instead, you define in the Pod's YAML how Kubernetes should "inject" that data.

First method is to define in the environment variables of pods/spec. So we can in the pod spec reference some config and then map it to some other service. In normal envs we define `-name and -value` with config map we use `valueFrom` where we define the `configMapKeyRef` and then define name of config map and key to inject. 

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: env-config-pod
spec:
  containers:
  - name: my-container
    image: nginx
    env:
      # Define the environment variable name
      - name: DB_URL 
        valueFrom:
          configMapKeyRef:
            name: app-config   # Name of the ConfigMap
            key: DATABASE_URL  # Key inside the ConfigMap
      - name: DB_PASSWORD
        valueFrom:
          secretKeyRef:
            name: db-secret    # Name of the Secret
            key: password      # Key inside the Secret
```

If your ConfigMap has 20 variables, you don't want to map them one by one. You can dump the entire ConfigMap into the container’s environment using envFrom

```yaml
spec:
  containers:
  - name: my-container
    image: nginx
    envFrom:
      - configMapRef:
          name: app-config
```
### Statefull sets

lets you run one or more related Pods that do track state somehow. Your code, running in the Pods for that StatefulSet, can replicate data to other Pods in the same StatefulSet to improve overall resilience.

### Deamon set

Defines Pods that provide facilities that are local to nodes. Every time you add a node to your cluster that matches the specification in a DaemonSet, the control plane schedules a Pod for that DaemonSet onto the new node. Each pod in a DaemonSet performs a job similar to a system daemon on a classic Unix / POSIX server.

### Job and cron jobs

These are jobs that run till completion and then stop. Job runs once only while cron job runs multiple times. 

## Controllers 

In robotics and automation, a _control loop_ is a non-terminating loop that regulates the state of a system.In Kubernetes, controllers are control loops that watch the state of your cluster, then make or request changes where needed. Each controller tries to move the current cluster state closer to the desired state.



#### Controller pattern 

A controller tracks at least one Kubernetes resource type. These objects have a spec field that represents the desired state. The controller(s) for that resource are responsible for making the current state come closer to that desired state. 

The Deployment controller and Job controller are examples of controllers that come as part of Kubernetes itself ("built-in" controllers). Kubernetes lets you run a resilient control plane, so that if any of the built-in controllers were to fail, another part of the control plane will take over the work.

## Kubernetes object management

The `kubectl` command-line tool supports several different ways to create and manage Kubernetes objects. In all there are three techniques of management

|Management technique|Operates on|Recommended environment|Supported writers|Learning curve|
|---|---|---|---|---|
|Imperative commands|Live objects|Development projects|1+|Lowest|
|Imperative object configuration|Individual files|Production projects|1|Moderate|
|Declarative object configuration|Directories of files|Production projects|1+|Highest|

When using imperative commands, a user operates directly on live objects in a cluster. The user provides operations to the `kubectl` command as arguments or flags.This is the recommended way to get started or to run a one-off task in a cluster. Because this technique operates directly on live objects, it provides no history of previous configurations.

Example 

Run an instance of the nginx container by creating a Deployment object:

```sh
kubectl create deployment nginx --image nginx
```

In imperative object configuration, the kubectl command specifies the operation (create, replace, etc.), optional flags and at least one file name. The file specified must contain a full definition of the object in YAML or JSON format.

```sh
kubectl create -f nginx.yaml
kubectl delete -f nginx.yaml -f redis.yaml
```

When using declarative object configuration, a user operates on object configuration files stored locally, however the user does not define the operations to be taken on the files. Create, update, and delete operations are automatically detected per-object by `kubectl`. This enables working on directories, where different operations might be needed for different objects.

Examples - 

```sh
kubectl diff -f configs/
kubectl apply -f configs/
```

We can also recursively process directories

```sh
kubectl diff -R -f configs/
kubectl apply -R -f configs/
```

Changes made directly to live objects are retained, even if they are not merged back into the configuration files.

### Namespaces

In Kubernetes, _namespaces_ provide a mechanism for isolating groups of resources within a single cluster. Names of resources need to be unique within a namespace, but not across namespaces.

Namespaces are intended for use in environments with many users spread across multiple teams, or projects. For clusters with a few to tens of users, you should not need to create or think about namespaces at all. By default there is namspace default. 


### Labels and selectors

Labels are the key/value pairs that are attached to the objects such as pod. Labels are intended to be used to specify identifying attributes of objects that are meaningful and relevant to users, but do not directly imply semantics to the core system. Labels can be used to organize and to select subsets of objects. Labels can be attached to objects at creation time and subsequently added and modified at any time. Each object can have a set of key/value labels defined. Each Key must be unique for a given object.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-deployment
  # 1. METADATA LABELS: Labels for the Deployment object itself.
  labels:
    app: frontend
spec:
  replicas: 3
  selector:
    # 2. SELECTOR: Tells the Deployment which Pods to "own".
    matchLabels:
      app: frontend
  template:
    metadata:
      # 3. TEMPLATE LABELS: Labels that will be "stamped" onto every Pod created.
      labels:
        app: frontend
    spec:
      containers:
      - name: nginx
        image: nginx:latest
```

Or by yaml 

```yaml
metadata:
  labels:
    app: nginx
```

Unlike uuids and names labels do not provide uniqueness. In general, we expect many objects to carry the same label(s).  Via a _label selector_, the client/user can identify a set of objects. The label selector is the core grouping primitive in Kubernetes. The API currently supports two types of selectors: _equality-based_ and _set-based_. A label selector can be made of multiple _requirements_ which are comma-separated. In the case of multiple requirements, all must be satisfied so the comma separator acts as a logical _AND_ (`&&`) operator.

Selectors can work with single label or multiple labels or can filter by existance

```sh
# Show pods that are part of the 'frontend' AND are in the 'production' environment
kubectl get pods -l app=frontend,env=prod
```



### Names and ids

Each object in cluster has a name that is unique for this type of resource. Every Kubernetes object also has a UID that is unique across your whole cluster.

