---
title: "5. Realtional databases"
description: "Note on 5. Realtional databases"
date: "2026-02-05"
tags: []
---


At its core, PostgreSQL stores data in tables (also called relations). Think of a table like a spreadsheet with rows and columns. Each column has a specific data type (like text, numbers, or dates), and each row represents one complete record.

Imagine we are creating a table

```sql
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

Each user gets a unique id (that's what PRIMARY KEY means), and we ensure no two users can have the same username or email (that's what UNIQUE does).

But users aren't much fun by themselves. They need to be able to post content. Here's where the "relational" part of relational databases comes in. We can create a posts table that's connected to our users:

```sql
CREATE TABLE posts (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

See REFERENCES users(id)? That's called a foreign key - it creates a relationship between posts and users. Every post must belong to a valid user, and PostgreSQL will enforce this for us. This is one of the key strengths of relational databases: they help maintain data integrity by enforcing these relationships.

There are three types of relations :

- one to one
- one to many
- many to many

Now, what if we want users to be able to like posts? This introduces a many-to-many relationship - one user can like many posts, and one post can be liked by many users. We handle this with what's called a join table:

```sql
CREATE TABLE likes (
    user_id INTEGER REFERENCES users(id),
    post_id INTEGER REFERENCES posts(id),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (user_id, post_id)
);
```

This structure, where we break data into separate tables and connect them through relationships, is called "normalization." It helps us:

- avoid duplicate data
- maintain data integrity
- make data model flexible

While normalization is generally good, sometimes we intentionally denormalize data for performance. For example, we might store a post's like count directly in the posts table even though we could calculate it from the likes table. This trade-off between data consistency and query performance is exactly the kind of thing you should discuss in your interview!


### SQL injection

SQL Injection (SQLi) is a deceptive technique where an attacker "injects" malicious SQL code into a query. This usually happens through a web input form, like a login box or a search bar, that hasn't been properly secured. Instead of entering a standard username, the attacker enters a string of database commands. If the application is vulnerable, it treats that malicious input as a legitimate instruction, allowing the attacker to bypass security measures and interact directly with the database.

At its core, the vulnerability stems from a lack of **input validation**. When a website takes user input and concatenates it directly into a string to build a database query, it creates a loophole. For example, if a system is looking for a user ID and someone enters `105 OR 1=1`, the database might see the `1=1` (which is always true) and return every single record in the table instead of just one. This can lead to unauthorized access to sensitive data, including passwords, credit card numbers, and personal user information.

```python
# WARNING: This code is vulnerable to SQL Injection
user_input = "admin' OR '1'='1"
query = "SELECT * FROM users WHERE username = '" + user_input + "';"

# The database executes: 
# SELECT * FROM users WHERE username = 'admin' OR '1'='1';
```

#### Prevention

**Prepared Statements (with Parameterized Queries):** This ensures that the database treats user input as data only, never as executable code. 

```python
# SAFE: Using parameterized queries
import sqlite3

connection = sqlite3.connect("example.db")
cursor = connection.cursor()

user_input = "admin' OR '1'='1"

# The '?' acts as a placeholder. 
# The library ensures the input is escaped and treated only as text.
cursor.execute("SELECT * FROM users WHERE username = ?", (user_input,))

results = cursor.fetchall()
```

**Stored Procedures:** Similar to prepared statements, these prevent the "mixing" of code and data.
**Input Validation:** Using "allow-lists" to ensure only expected characters (like numbers for a ZIP code) are submitted.
**Principle of Least Privilege:** Ensuring the database account used by the web application has only the bare minimum permissions required to function.

### Indexing 

In database management, an **index** is essentially a lookup table that the database search engine uses to find records faster. Without an index, the database has to perform a "Full Table Scan" reading every single row from start to finish which is fine for 10 rows, but a nightmare for 10 million.

A **Clustered Index** determines the physical order of data in a table. Because it dictates how the actual rows are stored on the disk, a table can have **only one** clustered index.
When you create a clustered index on a column (usually the Primary Key), the database sorts the entire table based on that column.Most databases automatically create a clustered index when you define a Primary Key.

A **Non-Clustered Index** is a separate structure from the data rows. It contains the values from the indexed columns and a **pointer** (a row locator) to the actual data row. The index is sorted, but the physical table remains in its original order (or the order of the clustered index). Since it’s a separate file/structure, you can have many non-clustered indexes on a single table (e.g., one for `Email`, one for `LastName`, etc.). To find data, the database searches the non-clustered index, finds the "pointer," and then performs a second step called a "Bookmark Lookup" to grab the rest of the row from the table.

Both types of indexes typically use a **B-Tree (Balanced Tree)** structure to find data. This is what makes searches so fast. Instead of looking at N rows, the database only has to look at log(N) levels.

While indexes make **Read** operations (SELECT) incredibly fast, they slow down **Write** operations (INSERT, UPDATE, DELETE). This is because every time you change a piece of data, the database must also update every index associated with that table.

There are many types of indexes - 

- Btree
- Hash indexing 
- Bitmap indexing
- R-tree
- Full text search
- Inverted indexing

#### B-trees 

B trees are self balancing trees where it has two kinds of nodes leaf nodes point to actual data in case of index is clustering and , block pointer in case of non-clustering data. Internal nodes always point to leaf nodes. Btrees provide `O(logn)` complexity for both exact and range queries. Speed is much faster in case searched using clustering index since leaf nodes point to actual data. 

### Hash index

A **Hash Index** uses a hash table to find data. It takes the value of your column, runs it through a hash function to get a "bucket" address, and goes straight there. In case there are very low number of collisions hash indexing works fastest for the exact search like email check etc. 

A **Bitmap Index** is used for columns with **low cardinality** columns where there are very few unique values (e.g., `Gender`, `MaritalStatus`, or `Boolean` flags). If you have a `Color` column with values "Red", "Blue", and "Green", the "Red" bitmap might look like `10010` (meaning the 1st and 4th rows are Red). **Boolean Logic:** This allows the database to perform extremely fast `AND`, `OR`, and `NOT` operations using bitwise math.

For other full text indexing see the postgres performance page. 

### Cursors

In the world of SQL, a **cursor** is a database object used to retrieve, manipulate, and navigate through a result set **one row at a time**.

Think of a standard SQL query (like `SELECT *`) as a "set-based" operation—it grabs a whole bucket of data at once. A cursor, by contrast, is an **iterative** tool. It acts like a pointer or a "blinking cursor" in a text document, moving line-by-line through the data so you can perform complex logic on each specific row.

To use a cursor, you must follow a specific sequence of commands, often referred to as the **DECLARE-OPEN-FETCH-CLOSE** cycle:

1. **DECLARE:** You define the cursor by giving it a name and assigning it a specific `SELECT` statement.
2. **OPEN:** The database executes the query and stores the result set in temporary memory (the context area).
3. **FETCH:** This is the "active" part. The cursor retrieves the current row and moves to the next one. You usually do this inside a loop.
4. **CLOSE:** Once you've processed all rows, you close the cursor to release the current result set.
5. **DEALLOCATE:** Finally, you delete the cursor definition and free up all system resources.



