# 5. Thread

---

A thread is a basic unit of CPU utilization; it comprises a thread ID, a program counter, a register set, and a stack. It shares with other threads belonging to the same process its code section, data section, and other operating-system resources, such as open files and signals. A proess in turn can be single threaded or multithreaded.

### Benefits

#### a. Responsiveness

Multithreading an interactive application may allow a program to continue running even if part of it is blocked or is performing a lengthy operation, thereby increasing responsiveness to the user.

#### b. Resource sharing

threads share the memory and the resources of the process to which they belong by default. The benefit of sharing code and data is that it allows an application to have several different threads of activity within the same address space.

#### c. Economy

Because threads share the resources of the process to which they belong, it is more economical to create and context-switch threads.

There are two kinds of parallelism

- Data parallelism- Focuses on distributing subsets of the same data across multiple computing cores and performing the same operation on each core.
- Task parallelism- Involves distributing not data but tasks (threads) across multiple computing cores.

### Multithreading models

There are two kinds of threads.

**User-level threads**(ULT) are threads that are **managed entirely in user space** by a thread library. The operating system kernel is **unaware** of the existence of multiple threads inside a process and treats the process as single-threaded.
From the **system perspective**, thread creation, scheduling, and context switching are very fast because they do not require system calls or kernel intervention. However, since the kernel schedules only the process and not individual threads, a **blocking system call by one thread blocks the entire process**.
From the **programmer’s perspective**, user-level threads are lightweight and efficient, making them suitable for applications with many short-lived threads. User level threads are very good when tasks are mostly IO bound because the task is executed on CPU for very small time and for most of the time waiting and since context switching is fast they are good. User level threads are very good for certain applications suchas webservers etc. Which are mostly I/O bound.

**Kernel-level threads**(KLT) are threads that are **directly supported and managed by the operating system kernel**. Each thread is known to the kernel and is scheduled independently.
At the **system level**, this allows **true parallelism** on multiprocessor systems, since different threads of the same process can run simultaneously on different CPUs. Blocking of one thread does not block the entire process. The trade-off is higher overhead, as thread creation, destruction, and context switching require kernel involvement.
From the **programmer’s perspective**, kernel-level threads are easier and safer to use.

Ultimately, a relationship must exist between user threads and kernel threads. In this section, we look at three common ways of establishing such a relationship: the many-to-one model, the one-to-one model, and the many-to-many model.

### Many to one model

Multiple user threads map to a single kernel thread. Thread management is done by the thread library in user space,so it is efficient. However entire process will get block if a thread meakes a blocking system call. Also, because only one thread can access the kernel at a time, multiple threads are unable to run in parallel on multicore systems.

### One to one model

The one-to-one model (Figure 4.6) maps each user thread to a kernel thread. It provides more concurrency than the many-to-one model by allowing another thread to run when a thread makes a blocking system call. It also allows multiple threads to run in parallel on multiprocessors. The only drawback to this model is that creating a user thread requires creating the corresponding kernel thread. Because the overhead of creating kernel threads can burden the performance of an application, most implementations of this model restrict the
number of threads supported by the system. Linux, along with the family of Windows operating systems, implement the one-to-one model.

### Many to many model

developers can create as many user threads as necessary, and the corresponding kernel threads can run in parallel on a multiprocessor. Also, when a thread performs a blocking system call, the kernel can schedule another thread for execution.
