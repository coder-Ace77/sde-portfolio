---
title: "7. Scheduling"
description: ""
date: "2026-02-05"
---



Recap of multiprogamming model here we keep multiple process in memory at a time. When one process waits for i/o to be completed the OS takes away the cpu from that process and allocates it to some other process. 
A process always alternates between two states I/O burst and CPU burst. A process always begins with CPu burst. 

An I/O boud process has many short cpu burst while a cpu bound process has few long bursts.

## CPU scheduler

Whenever the CPU becomes idle, the operating system must select one of the processes in the ready queue to be executed. The selection process is carried out by the short-term scheduler, or CPU scheduler.

CPU scheduler can be invoked when - 

- Process switches from running to waiting
- running to ready state
- waiting to ready state
- terminates

Under nonpreemptive scheduling, once the CPU has been allocated to a process, the process keeps the CPU until it releases the CPU either by terminating or by switching to the waiting state. In preemptive a process running can be prempt out by another process. Unfortunately, preemptive scheduling can result in race conditions when data are shared among several processes.

A dispatcher is the module of the operating system that gives control of the CPU to the process selected by the CPU scheduler. A dispacther whne allocatiing some process a cpu has to do three things-

- Switch context
- Switch to user mode
- Jump to proper location

Dispatch latency is the time taken in stoping a process and starting another one and is pure overhead. 

CPU utilization is the percentage of total cpu usage. In ideal case we want high cpu usage. 
Throughput - number of process completed per unit time.
Turn around time - Time from submission to completion (time spent in different queues + time spent in CPU + time spent in different i/o
devices)
Waiting time- time spent in ready queue (only)
Response time - Time from submission to first response

## Scheduling algorithms

### FCFS(first come first serve)

The process who requests cpu first gets the cpu first and can be implemented using FIFO queue. Average waiting time can often be very long for the FCFS becasue one long running process can block other short running processes and average waiting time can be quite large.
FCFS is non premptive. And has a big flaw of convey effect where all the smaller process wait for the big process to get off the cpu. 

Schenario- 

Consider one cpu bound process and other i/o bound process. say cpu bound process gets the cpu and i/o bound prcess are doing i/o when they are done i/o bound process wait at the ready queue. And once the cpu bound process is done other i/o will be done quickly and thus cpu sits idle for the time. The CPU-bound process will then move back to the ready queue and be allocated the CPU. Again, all the I/O processes end up waiting in the ready queue until the CPU-bound process is done. This here is convey effect which here is conveying the lowering of cpu utilization to other processes. 

### SJF(Shortest Job first)

This algorithm associates with each process the length of the process’s next CPU burst.When the CPU is available, it is assigned to the process that has the smallest next CPU burst. Note that a more appropriate term for this scheduling method would be the shortest-next-CPU-burst algorithm, because scheduling depends on the length of the next CPU burst of a process, rather than its total length.

The SJF scheduling algorithm is provably optimal, in that it gives the minimum average waiting time for a given set of processes. Moving a short process before a long one decreases the waiting time of the short process more than it increases the waiting time of the long process. Consequently, the average waiting time decreases.

The real difficulty is knowing the time of next cpu burst. Although the SJF algorithm is optimal, it cannot be implemented at the
level of short-term CPU scheduling. With short-term scheduling, there is no way to know the length of the next CPU burst.

One way is to predict the time of next burst. We expect that the next CPU burst will be similar in length to the previous ones. By computing
an approximation of the length of the next CPU burst, we can pick the process with the shortest predicted CPU burst.

`t(n+1)=at(n)+(1-a)u(n)`

Here `t(n)` means th burst time of `nth` burst and is used to store the history. The higher the value of `a` higher is the waeight of recent event and lower weightage to history. 

`u(n+1)=at(n)+(1-a)t(n-1)+..+(1-a)^jat(n-j)` a is typically less than 1. 

SJF can either be preemtive or non preemtive. The choice arises when a new process arrives at the ready queue while a previous process is
still executing. The next CPU burst of the newly arrived process may be shorter than what is left of the currently executing process. A preemptive SJF algorithm will preempt the currently executing process, whereas a nonpreemptive SJF algorithm will allow the currently running process to finish its CPU burst. Preemptive SJF scheduling is sometimes called shortest-remaining-time-first scheduling.

### Priority scheduling 

The SJF algorithm is a special case of the general priority-scheduling algorithm.A priority is associated with each process, and the CPU is allocated to the process with the highest priority. Equal-priority processes are scheduled in FCFS order. An SJF algorithm is simply a priority algorithm where the priority (p) is the inverse of the (predicted) next CPU burst. The larger the CPU burst, the lower the priority, and vice versa.

Priorities are generally indicated by some fixed range of numbers, such as 0 to 7 or 0 to 4,095. However, there is no general agreement on whether 0 is the highest or lowest priority. Some systems use low numbers to represent low priority; others use low numbers for high priority. This difference can lead to confusion. In this text, we assume that low numbers represent high priority.

Priorities can be defined either internally or externally. Internally defined priorities use some measurable quantity or quantities to compute the priority of a process. For example, time limits, memory requirements, the number of open files, and the ratio of average I/O burst to average CPU burst have been used in computing priorities. External priorities are set by criteria outside the operating system, such as the importance of the process, the type and amount of funds being paid for computer use, the department sponsoring the work, and other, often political, factors.

Priority scheduling can be either preemptive or nonpreemptive. When a process arrives at the ready queue, its priority is compared with the priority of the currently running process. A preemptive priority scheduling algorithm will preempt the CPU if the priority of the newly arrived process is higher than the priority of the currently running process. A nonpreemptive priority scheduling algorithm will simply put the new process at the head of the ready queue.
A major problem with priority scheduling algorithms is indefinite blocking, or starvation. A process that is ready to run but waiting for the CPU can be considered blocked. A priority scheduling algorithm can leave some low-priority processes waiting indefinitely.

A solution to the problem of indefinite blockage of low-priority processes is aging. Aging involves gradually increasing the priority of processes that wait in the system for a long time. For example, if priorities range from 127 (low) to 0 (high), we could increase the priority of a waiting process by 1 every 15 minutes.

### Round robin 

The round-robin (RR) scheduling algorithm is designed especially for time-sharing systems. It is similar to FCFS scheduling, but preemption is added to enable the system to switch between processes. A small unit of time, called a time quantum or time slice, is defined. A time quantum is generally from 10 to 100 milliseconds in length. The ready queue is treated as a circular queue.

To implement RR scheduling, we again treat the ready queue as a FIFO queue of processes. New processes are added to the tail of the ready queue. The CPU scheduler picks the first process from the ready queue, sets a timer to interrupt after 1 time quantum, and dispatches the process. One of two things will then happen. The process may have a CPU burst of less than 1 time quantum. In this case, the process itself will release the CPU voluntarily. The scheduler will then proceed to the next process in the ready queue. If the CPU burst of the currently running process is longer than 1 time quantum, the timer will go off and will cause an interrupt to the operating system. A context switch will be executed, and the process will be put at the
tail of the ready queue. The CPU scheduler will then select the next process in the ready queue.

The waiting time of RR algo is often very high. RR scheduling is always preemtive. If in total n process and time quantm is q then anyone process has to wait `(n-1)q` to get next cpu burst. Now the performance of system depends heavily in the time quantum if time quantum is too large most of the proceses will end before switch and with too small time quantum most of time of quantum will go in context switch rather than execution. 

### Multilevel queue scheduling

This is when ready queue is partitioned into multiple queues based on claases of process (foreground and background). The processes are permanently assigned to one queue, generally based on some property of the process, such as memory
size, process priority, or process type. Each queue has its own scheduling algorithm.
In addition, there must be scheduling among the queues, which is commonly implemented as fixed-priority preemptive scheduling. For example, the foreground queue may have absolute priority over the background queue.
Another possibility is time slicing of queues Here, each queue gets a certain portion of the CPU time, which it can then schedule among its various processes.

![Pasted image 20260111094433.png](/notes-images/Pasted%20image%2020260111094433.png)
### Multilevel feedback queue

Normally, when the multilevel queue scheduling algorithm is used, processes are permanently assigned to a queue when they enter the system.
The multilevel feedback queue scheduling algorithm, in contrast, allows a process to move between queues. The idea is to separate processes according to the characteristics of their CPU bursts. If a process uses too much CPU time, it will be moved to a lower-priority queue. This scheme leaves I/O-bound and interactive processes in the higher-priority queues. In addition, a process that waits too long in a lower-priority queue may be moved to a higher-priority queue. This form of aging prevents starvation. 

![Pasted image 20260111094518.png](/notes-images/Pasted%20image%2020260111094518.png)

### Multiprocessor scheduling


CPU scheduling types 

- asymmetric multiprocessing  - one processor performs scheduling for all
- symmetric multiprocessing - each processor is self-scheduling

processor affinity –
- because of high cost of invalidating and repopulating caches, migration of processes
from one processor to another is avoided
- attempt is made to keep a process at a given processor
- hard- and soft- affinity

load balancing –
- attempt to keep all processors equally loaded
- pull migration, push migration, combination
- only for symmetric systems
- counteracts the benefits of processor affinity

### Ghant chart

A **Gantt chart** in CPU scheduling is a **timeline diagram** that shows **how the CPU is allocated to different processes over time**. It helps visualize **process execution order, start time, finish time, and idle time** for a given scheduling algorithm.

eg 

```
| P1 | P2 | P3 | P1 |
0    4    7    10   12
```


