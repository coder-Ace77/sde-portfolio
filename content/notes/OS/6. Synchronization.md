
---

Two process can share the common memory. Now in multiprocessing systems one process may partially complete the execution and may by interupted at any time. Secondly two processes can be running at the same time on different cpu's. 

### Bounded buffer

Communication happens in processes using shared memory. In this regard processes follow bounded buffer where one process will be producing something and other will be consuming something. This forms one side of communication. To have full duplex connection we need to have two bounded buffers. 

A bounded buffer is a bounded memory having upper limit `BUFFER_SIZE`. Bounded buffer at the high level can be considered as the array. However we need to be able to manage the orchestration of used space and given space. Basically tracking the space used or left. 

The `++` instruction at machine level consists of atleast three machine instructions. 

```
R1 = counter // load
R1 = R1 + 1 
counter = R1 // store
```

The concurrent exection is equivalent to the sequencial execution in which instructions are interleaved in certain manner.

We would arrive at this incorrect state because we allowed both processes to manipulate the variable counter concurrently.

A situation like this, where several processes access and manipulate the same data concurrently and the outcome of the execution depends on the particular order in which the access takes place, is called a race condition.To guard against the race condition above, we need to ensure that only one process at a time can be manipulating the variable counter. To make such a guarantee, we require that the processes be synchronized in some way.

Note that race conditions are prone to happen if multiple process can progress in parallel regardless of if there are more than one processors or not. 

### Critical section problem 

Any set of `n` processes have a segment of code called `critical section` in which each process may be changing common variables, updating tables , writing files and so on. The problem is to design a system with three requirements:

- Mutual exclusion - If a process is executing in critical section no other process can be executing in critical section. 
- Progress - If no process is executing in its critical section and some processes wish to enter their critical sections, then only those processes that are not executing in their remainder sections can participate in
deciding which will enter its critical section next, and this selection cannot be postponed indefinitely.
- Bounded waiting - There exists a bound, or limit, on the number of times that other processes are allowed to enter their critical sections after a process has made a request to enter its critical section and before that
request is granted.

Now a process can be in user mode or kernel mode. A process in user mode can always be interrupted. However the process in kernel mode is tricker reason being it may have various datastructures opened and may try to update at the same time leading to race condition. Kernel data structures that are prone to possible race conditions include structures for maintaining memory allocation, for maintaining process lists,
and for interrupt handling.

Now two approaches used to solve this problem are - 

- Preemptive kernel - OS allows process to be prempted. This means possible race conditions. 
- Non preemptive kernel - OS does not allow the process to be prempted and is free from race conditions. 

Non premptive kernel are non responsive in real time and it is their biggest flaw. With preemptive kernels we need to have special mechanism to solve the issue. 

### Peterson solution to critical section problem

Peterson's solution is the early solution to the critical section problem. It is a software solution and may not work on modern computers. This solution works only for two processes. 

Peterson solution has two data structures- 

- turn - determines the tie breaker
- `flag[]` - intent on who wants to enter

```cpp
flag[i]=true;
turn = j;
while(flag[j] && turn!=i);
// critical section
flag[i]=false;
```

Note down certain things - 

if flag is not there then processes will be waiting without intent. Condition when atleast one of them has `turn=i` but it does not want to go in and `j` wants to go in the critical section. 
With out turn there will be a deadlock. So both are necessary. 

It can be seen that both process first state the intent to enter and then put allow the other one to enter by putting `turn=j`. Since turn can be either i or j this means only one can enter the critical section. 

The solution may not work for the modern systems as the order of operations may get reversed during execution. Note that `turn` update must be the final statement to get executed to get this solution corrected. 

For example 

```
turn = j;
flag[i] = true;
```

This will voilates the mutual exclusion as both can see the their turn simultaneously. 

### Synchronization hardware

There are two sets of instructions provided by the hardware (cpu) instruction set. These are the tools provided by the cpu instruction set itself. Both of them are atomic and are used to implement the more sophisticated locking mechanism. 

#### test and set :

This is an atomic operation(meaning can not be interputed) which takes a memory location checks for the truth value of variable and then sets it to true. Logically it is equivalent to but is atomic in its entirety.

```cpp
bool test_and_set(bool *val){
	bool rv=*val;
	*val=true;
	return rv;
}
```

### compare and swap

This is again atomic and takes one variable compares it value in refernece to some exprected value(compare) and then changes the value to new value(swap) if and if compare results to true and finally returns the older value.

```cpp
int compare_and_swap(int *value,int expected,int new_value){
	int temp=*value;
	if(temp==expected)*value=new_value;
	return temp;
}
```

Now these can be used to solve the mutual exclusion problem(not the entire critical section problem). 
Here lock is intialised to `0`. Then we compare the value and if it is `0` meaning we can enter critical section and then value is updated to 1. 

```cpp
while(compare_and_swap(&lock,0,1)!=0){
	// critical section
	lock=0;
}
```

## Mutex locks

These hardware instructions are inaccessible to the programmers and so Operating systems provide the software tools to solve the critical section problem. The simplest of these tools is `mutex` locks. 

Mutex locks api have just two functions-

1. aquire() - eg `lock.aquire()` A mutex lock has a boolean variable available whose value indicates if
the lock is available or not. If the lock is available, a call to acquire() succeeds, and the lock is then considered unavailable. A process that attempts to acquire an unavailable lock is blocked until the lock is released.
2. release() - release just turns the value of available to be true and moves further. Calls to either acquire() or release() must be performed atomically. Thus, mutex locks are often implemented using one of the hardware mechanisms. 

Now basic definition of mutex locks can be given as - 

```cpp
acquire(){
	while(!available);
	available=false;
}
```

Now that available should here be checked in the atomic manner. More often than not the implementation is much more involved using the atomic hardware instruction inside. This kind of locks are also called spin locks because the process spins waiting for the lock to become available. 

Another way is that process blocks itself and puts itself in the waiting queue and when lock is available the process be put into the ready queue. The important point is that spin locks are good if the wait is just for small time. For example just updating a memory location because no context switching is needed. Suspend and resume will work good if process needs to wait for large time. 

### Semaphores

Semaphore are another synchronization tools it can act as basic mutex lock but it can programmed to act in more sophisticated ways. A semaphore is a integer variable whose value apart from initalization can be changed by the two atomic operations only `wait()/acquire()` and `signal()/release()`.  

Definition is as - 

```cpp
wait(S){
	while(S<=0); // wait
	S--;
}

signal(S){ 
	S++;
}
```

Now by this definition the semaphore value can be initialized to be any value. It however will wait if semaphore value is `0`.
Both the operations are atomic and indivisible. OS distinguish between `counting` and `binary` semaphores. The value of `binary semaphore` can reange over unrestricted domain. The value of binary semaphore can range in between `0-1`. Binary semaphores can act similar to semaphores. 

Counting semaphores can be used to give the control access to a given resource consisting finite number of instances. It is also employed in wide variety of  advanced concurrency algorithms. 

Note that in java we have mutex and semaphores both but api is little different from standard.

```java

// semaphore
Semaphore s = new Semaphore(1);
s.acquire();
s.release();

// lock
ReentrantLock l = new ReentrantLock();
l.lock();
l.unlock();
```

Similarly semaphore can be implemented in both ways context switch or busy waiting. Note that in the context switch implementation value of semaphore may be neagaitve while the value of valriable will neverbe negative in the classical definition. 

### Deadlocks and starvation

The implementation of a semaphore with a waiting queue may result in a situation where two or more processes are waiting indefinitely for an event that can be caused only by one of the waiting processes. When such a state is reached, these
processes are said to be deadlocked. 

Another problem related to deadlocks is indefinite blocking or starvation, a situation in which processes wait indefinitely within the semaphore. Indefinite blocking may occur if we remove processes from the list associated with a semaphore in LIFO (last-in, first-out) order.

A scheduling challenge arises when a higher-priority process needs to read or modify kernel data that are currently being accessed by a lower-priority process—or a chain of lower-priority processes. Since kernel data are typically protected with a lock, the higher-priority process will have to wait for a lower-priority one to finish with the resource. This problem is known as priority inversion. It occurs only in systems with more than two priorities, so one solution is to have only two priorities.

## Classical synchronization problems 


### Bounded buffer problem

The **Bounded Buffer Problem** is a classic **synchronization problem** in operating systems and concurrent programming.

It involves:
- A **fixed-size buffer** (limited capacity)
- One or more **producer** processes that generate data and put it into the buffer
- One or more **consumer** processes that remove data from the buffer and use it

- A **producer** must **not add** data if the buffer is **full**
- A **consumer** must **not remove** data if the buffer is **empty**
- Producers and consumers must **not access the buffer simultaneously** in a way that causes data inconsistency.


### Solution

We have to manage two things consumer must wait untill there is something to be consumed and producer should wait untill buffer is full and both should not access the bufffer simultaneosly. 

To do that we will be using two semaphores one tracking empty area blocks the producer and other tracking the full area blocks the consumer and one more lock so that all the datastructes can not be accessed simultaneosly. 

```java
import java.util.concurrent.Semaphore;

class Buf {
    int[] a;
    int in = 0, out = 0;
    Semaphore empty, full, mutex;

    Buf(int n) {
        a = new int[n];
        empty = new Semaphore(n);
        full = new Semaphore(0);
        mutex = new Semaphore(1);
    }

    void put(int x) throws InterruptedException {
        empty.acquire();
        mutex.acquire();
        a[in] = x;
        in = (in + 1) % a.length;
        mutex.release();
        full.release();
    }

    int get() throws InterruptedException {
        full.acquire();
        mutex.acquire();
        int x = a[out];
        out = (out + 1) % a.length;
        mutex.release();
        empty.release();
        return x;
    }
}

class P extends Thread {
    Buf b;
    P(Buf b) { this.b = b; }
    public void run() {
        try {
            for(int i = 0; i < 10; i++) b.put(i);
        } catch(Exception e) {}
    }
}

class C extends Thread {
    Buf b;
    C(Buf b) { this.b = b; }
    public void run() {
        try {
            for(int i = 0; i < 10; i++)b.get();
        } catch(Exception e) {}
    }
}

public class Main {
    public static void main(String[] args) {
        Buf b = new Buf(5);
        new P(b).start();  // P = Producer
        new C(b).start(); // C = consumer
    }
}
```

Producer block
```java
 void put(int x) throws InterruptedException {
	  empty.acquire();
	  mutex.acquire();
	  a[in] = x;
	  in = (in + 1) % a.length;
	  mutex.release();
	  full.release();
 }
```

Note that it first checks if there are empty block or not if it gets on it immediately applies mutex so that consumer can not consume and manipulate the DS essentially eliminatiing the race conditions. Now the item is put and mutex is released. Finally full is released so that another consumer can consume. 

Consumer block
```java
int get() throws InterruptedException {
	  full.acquire();
	  mutex.acquire();
	  int x = a[out];
	  out = (out + 1) % a.length;
	  mutex.release();
	  empty.release();
	  return x;
 }
```

The consumer block also works in much of the same way. First it checks and waits for if any of the slots is full. Then acquires the mutex and empty out the buffer. 

### Reader writer problem 

The **Reader–Writer Problem** is a classic **process synchronization problem**.

It involves:
- A **shared data resource** (e.g., file, database, memory)
- Multiple **reader** processes that only **read** the data
- Multiple **writer** processes that **modify** the data

### Rules

- **Multiple readers** can access the shared resource **simultaneously**
- **Writers require exclusive access** (no readers or other writers at the same time)
- Readers must not read while a writer is writing
- Writers must not write while readers are reading

There are two variations to it. In first reader-writer problem writer has to wait untill atleast one process is reading. In second reader-writer problem writer will block all the new readers. In the first case writer may starve and in the second case reader may starve. 

##### Solution to first reader writer problem

It is easier to solve as once someone has got the shared lock they keep it. One thing to keep in mind is that mutex will be used to protect the cnt variable. When cnt will be one meaning first reader then it has to get the rw_mutex and once reader counter goes to `0` It will have to release it. 

```cpp

Semaphore rw_mutex = 1;
Semaphore mutex = 1;
int cnt =0; // to find how many readers 

// writer
wait(rw_mutex);
// write
signal(rw_mutex);

// reader
wait(mutex)
cnt++;
if(cnt==1)
	wait(rw_mutex)
signam(mutex)

// read

wait(mutex)
cnt--;
if(cnt==0)
	signal(rw_mutex)
signal(mutex)
```

##### Solution to second reader writer problem

**Second Readers–Writers Problem (writers priority)**  
Goal: if a writer is waiting, no new reader should enter. Todo that we have readTry lock which will be held up by writer and reader in start need to have this to move further. This acts as blocker. 

```java
import java.util.concurrent.Semaphore;

class RW {
    int rc = 0;
    Semaphore rmutex = new Semaphore(1);
    Semaphore wmutex = new Semaphore(1);
    Semaphore readTry = new Semaphore(1);

    void read() throws InterruptedException {
        readTry.acquire();
        rmutex.acquire();
        rc++;
        if (rc == 1) wmutex.acquire();
        rmutex.release();
        readTry.release();

        // reading

        rmutex.acquire();
        rc--;
        if (rc == 0) wmutex.release();
        rmutex.release();
    }

    void write() throws InterruptedException {
        readTry.acquire();
        wmutex.acquire();

        // writing

        wmutex.release();
        readTry.release();
    }
}
```

### Dining philospher problem

There are **N philosophers** sitting around a **circular table**. Between each pair of adjacent philosophers, there is **one fork** (so N forks total). Each philosopher alternates between two states:

- **Thinking**
- **Eating**

To **eat**, a philosopher must hold **both forks** adjacent to them:

- the **left fork**
- the **right fork**

The rules/constraints are:

1. A philosopher can only pick up **one fork at a time**.
2. A fork can be held by **only one philosopher at a time**.
3. After eating, the philosopher must **put down both forks** before thinking again.
4. Philosophers do not communicate with each other.

The challenge is to design a protocol such that:

- **No deadlock** occurs (e.g., all philosophers pick up one fork and wait forever for the other).
- **No starvation** occurs (every philosopher eventually gets to eat).
- **Maximum concurrency** is allowed (philosophers should eat whenever possible).

This problem models real-world scenarios where **multiple processes compete for limited shared resources** and highlights the difficulties of coordinating access without conflicts.

##### Solution 1

To allocate a different semaphore to each chopstick. A philospher has to get both the chopsticks before eating. But this appraoch can create deadlock. 

```cpp
Semaphore m[5];
wait(m[i]);
wait(m[(i+1)%5]);

// eat

signal(m[i])
signal(m[(i+1)%5]);
```

##### Solution 2

Allow atmost 4 philosphers to a time. To do that we will introduce one more semaphore room. Which will start at 4. This is deadlock free as atmost 4 philosphers can start to pick and there are 5 chopsticks. By pigeon hole principle atleast one philospher will get 2 chopsticks. 

```cpp
Semaphore m[5]={1};
Semaphore room = 4;

// philosphers code

wait(room);
wait(m[i]);
wait(m[(i+1)%5]);
// eat

signal(m[i])
signal(m[(i+1)%5]);
signal(room);
```

However starvation is still possible as now all the philosphers are guaranteed fairness. 

##### Pick up both chopsticks

Here a philospher tries to pick both of the chopsticks atomically and will pick either both or none. This again is deadlock free but not starvation free. 

```cpp
Semaphore mutex = 1;
Semaphore m[5] = {1};

// philosopher i

wait(mutex);
if (m[i] == 1 && m[(i+1)%5] == 1) {
    wait(m[i]);
    wait(m[(i+1)%5]);
}
signal(mutex);

// eat

signal(m[i]);
signal(m[(i+1)%5]);
```

Note that solution blocks all the philosphers to acquire the chopstick if one is trying to acquire. This leads to very bad performance as during acquire phase only one philospher will be able to go inside. 
##### Asymetric solution 

Break symmetry by making philosophers behave differently. Even numbered philosphers pick left first while odd number philosphers pick right one first. 

```cpp
Semaphore m[5] = {1};

// philosopher i

if (i % 2 == 0) {
    wait(m[i]);
    wait(m[(i+1)%5]);
} else {
    wait(m[(i+1)%5]);
    wait(m[i]);
}

// eat

signal(m[i]);
signal(m[(i+1)%5]);

```

##### Final solution using states

To ensure fairness is one of the key steps we have ignored till now. In this solution a philospher can be in three states. `THINKING`,`HUNGRY`,`EATING`. A philospher is allowed to eat if she is hungry and left and right neighbours are not eating. A phiolospher is allowed to eat if only they are hungry and her left and right neighbours are not eating. The big point here is when a philospher is finished eating they awake their neighbours to ensure fareness. 

```cpp
Semaphore mutex = 1;
Semaphore self[5] = {0};

state[5] = {THINKING};

// helper
test(i):
    if state[i] == HUNGRY
       and state[(i+4)%5] != EATING
       and state[(i+1)%5] != EATING
    then
        state[i] = EATING
        signal(self[i])

// philospher i
wait(mutex);
state[i] = HUNGRY;
test(i);
signal(mutex);

wait(self[i]);

// eat

wait(mutex);
state[i] = THINKING;

test((i+4)%5);
test((i+1)%5);

signal(mutex);
```

If the neighbours are not eating philospher will change the state to eating otherwise it will sleep. At this poijnt philospher will never try to eat again but rather neighbours will give it opportunity back to eat. In this way it works. see the final test. 

### Monitors

A **monitor** is a **high-level synchronization construct** used to control access to **shared data** in concurrent systems.The fundamental idea behind monitors is that **only one thread/process can be active inside a monitor at any given time**, which automatically enforces **mutual exclusion** without requiring programmers to explicitly write `wait` and `signal` logic for mutual exclusion every time.

In java the synchronization blocks and methods are examples of monitors. 

At runtime, a monitor maintains an **internal lock** (mutex) that ensures only one thread can execute inside the monitor at any moment any other thread attempting to enter is placed in an **entry queue** and blocked until the lock becomes available. When a thread is inside the monitor but cannot proceed because a required condition on the shared state is false, it executes a `wait` operation on a condition variable, which causes the thread to atomically release the monitor lock and go to sleep on that condition’s waiting queue. Releasing the lock allows another blocked thread to enter the monitor and potentially change the shared state. When a thread modifies the state in a way that may satisfy a waiting condition, it calls `signal` on the corresponding condition variable, which wakes one waiting thread (or all, in the case of broadcast) and moves it to the ready state. The awakened thread will re-enter the monitor after reacquiring the lock and recheck the condition before continuing execution.


> [!NOTE] Condition variable
> A **condition variable** is a synchronization mechanism used **inside monitors** to allow a thread to **sleep until a particular condition on shared data becomes true**. While mutual exclusion ensures that only one thread accesses shared data at a time, condition variables solve a different problem: **how a thread can wait efficiently for a specific state change without busy waiting**.
> A condition variable supports two fundamental operations:
> - wait(c) - Tells to release the monitor lock and sleep on condition variable allow other thread to enter.
> - Signal(c) wakes another thread that is sleeping on condition variable, 
> Internally the conditional variable holds a blocking queue and when wait is called and thread can not progress it is put into that queue. When other threads give signal then one thread/ process is kept out of the queue and is resumed. 
