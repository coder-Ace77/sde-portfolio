# 6. Scc And Functional Graph

---

## Functional graph

A **functional graph** on `n` nodes is a directed graph where **each node has exactly one outgoing edge**.Here, `f(v)` is the _function_ that maps node `v` to another node (possibly itself).

So, if you imagine each node as representing an element `v`, and the function `f(v)` tells you where to “go next,” then following the edges repeatedly is like applying the function over and over again:

`v → f(v) → f(f(v)) → f(f(f(v))) → ...`

1. **Indegree can be 0, 1, or more**
2. **The graph consists of one or more disjoint components**
3. **Each component contains exactly one directed cycle** - Because if you keep following the unique outgoing edges, you must eventually revisit a node (pigeonhole principle)
4. **Every node is either on the cycle or leads into it (a tree attached to a cycle)**
5. Each component will have exactly one cycle. And some tree or sangling nodes attach to it.
6. When starting dfs from any node it will eventually enter some cycle.

![Alt](/img/Pasted_image_20251021111149.png)

Note that two cycles can not be overlapping here.

Problems

1. For each node, determine which cycle (component) it eventually enters.You can do this using DFS, or an iterative approach with visited arrays.
2. Find the length of the cycle a node belongs to or reaches.
3. For nodes not in a cycle, find how many steps it takes to reach the cycle.
4. - Given `f` and a node `v`, find `f^k(v)` (the node reached after applying `f` `k` times). This is a classic **binary lifting** application.

Note that topological sorting alogorithms can be used to detect a cycle but not to find the all the cycles. In case of functional programming however they can.

Detecting cycles and distances using topo - Here

We can use DFS or iterative “visited state” methods to find cycles and distances to cycles.

Each node can have one of three states:

- `0` = unvisited
- `1` = visiting (currently in recursion stack)
- `2` = processed

When you visit a node:

- If you reach a node with state `1`, you found a cycle.
- If you reach a node with state `2`, you can use its result to compute yours.

```cpp
#include <bits/stdc++.h>
using namespace std;

const int N = 1e5 + 5;
int n;
int f[N];
int state[N];     // 0 = unvisited, 1 = visiting, 2 = done
int distToCycle[N];
int cycleLen[N];

void dfs(int v) {
    state[v] = 1;
    int u = f[v];
    if (state[u] == 0) {
        dfs(u);
        distToCycle[v] = distToCycle[u] + 1;
        cycleLen[v] = cycleLen[u];
    } else if (state[u] == 1) {
    // found a cycle
    int len = 1;
    for (int x = f[u]; x != u; x = f[x]) len++;
    // mark all nodes in this cycle
    for (int x = u;; x = f[x]) {
        distToCycle[x] = 0;
        cycleLen[x] = len;
        state[x] = 2;
        if (f[x] == u) break;
    }
} else {
// already processed node
distToCycle[v] = distToCycle[u] + 1;
cycleLen[v] = cycleLen[u];
}
state[v] = 2;
}

```

Find the total nodes in the cycles in functional graph -
Ans: This problem can be solved very easily repeaditly deleting all the nodes with indeg 0. In the end only cycles will remain.

## Strongly connected components

A directed graph often hides rich structure: groups of vertices that are tightly interlinked and behave like a single unit from the point of view of reachability. Those groups are called **strongly connected components (SCCs)**. Informally, an SCC is a maximal set of vertices such that for every ordered pair of vertices `u, v` in the set there is a directed path from `u` to `v` and also from `v` to `u`.

In other words, within an SCC every vertex can reach every other vertex. SCCs partition the vertex set of any directed graph and form the basic atoms from which the global structure of the graph can be understood: collapsing each SCC to a single node produces the **condensation graph**, which is always a directed acyclic graph (DAG). This simple observation about SCCs — that the condensation is a DAG — is key to many algorithmic reductions and applications.

### SCC basics

The mathematical definition of strongly connected components immediately implies some useful consequences. First, SCCs form a partition of vertices: every vertex belongs to exactly one SCC. Second, if you contract each SCC into a single vertex, the resulting condensation graph has no cycles; all edges between components go one way only, producing a partial order on SCCs. That DAG is extremely helpful: reachability questions, topological reasoning, and dynamic programming on directed graphs often become much simpler on the condensed DAG.

Practically, SCCs are used to identify cyclic dependencies in compilation units, to detect groups of mutually dependent modules, to solve logical satisfiability problems (e.g., 2-SAT), to analyze reachability in program analysis or web graphs, and to reduce graphs before running other expensive graph algorithms. Because SCC identification is linear in the size of the graph, it is a common preprocessing step in many graph-based pipelines.

### Algorithms

There are a handful of classic algorithms to compute SCCs efficiently. The most widely used are Kosaraju’s algorithm, Tarjan’s algorithm, and Gabow’s algorithm. All of them run in linear time `O(V + E)` and use only linear additional space beyond the graph itself, but they differ in practical details: whether they need the reverse graph, how they manage stack/state, and how easily they support iterative implementations.

Kosaraju’s algorithm is conceptually the simplest to understand and implement. It consists of two passes of depth-first search (DFS). In the first pass you run a DFS over the original graph and record vertices in a list in the order of finishing times (push onto a stack or vector when the DFS finishes a vertex). In the second pass you traverse the **reversed graph** (every edge reversed) and repeatedly start DFS from the vertex with the highest finishing time not yet assigned to a component; each DFS in the reversed graph discovers exactly one SCC. Kosaraju is robust and easy to reason about; the only practical annoyance is that you must materialize (or be able to traverse) the reversed graph.

```cpp
void dfs1(int v, const vector<vector<int>>& adj, vector<int>& vis, vector<int>& order) {
    vis[v] = 1;
    for (int u : adj[v]) if (!vis[u]) dfs1(u, adj, vis, order);
    order.push_back(v);
}

void dfs2(int v, const vector<vector<int>>& radj, vector<int>& comp, int cid) {
    comp[v] = cid;
    for (int u : radj[v]) if (comp[u] == -1) dfs2(u, radj, comp, cid);
}

vector<int> kosaraju(int n, const vector<vector<int>>& adj) {
    vector<int> vis(n, 0), order; order.reserve(n);
    for (int i = 0; i < n; ++i) if (!vis[i]) dfs1(i, adj, vis, order);

    // build reversed graph
    vector<vector<int>> radj(n);
    for (int v = 0; v < n; ++v) {
        for (int u : adj[v]) radj[u].push_back(v);
    }

    vector<int> comp(n, -1);
    int cid = 0;
    for (int i = n - 1; i >= 0; --i) {
        int v = order[i];
        if (comp[v] == -1) {
            dfs2(v, radj, comp, cid++);
        }
    }
    return comp; // comp[v] in [0, cid-1]
}

```

Tarjan’s algorithm is an elegant single-pass DFS that computes SCCs without ever explicitly reversing the graph. It assigns each vertex an index as it is discovered and maintains a low-link value that represents the smallest discovery index reachable from that vertex through its DFS subtree (possibly using back edges). Tarjan pushes vertices onto a stack as they’re visited and when a node’s index equals its low-link, the algorithm pops the stack until that node, and all popped vertices form an SCC.

Tarjan’s method is memory efficient (no reversed graph), usually faster in practice because it requires only one DFS and straightforward bookkeeping, and it produces SCCs in reverse topological order of the condensation DAG. A caveat is that Tarjan uses recursion, so for extremely deep graphs you must ensure recursion depth is safe or convert to an iterative version.

```cpp
struct TarjanSCC {
    int n;
    vector<vector<int>> adj;
    vector<int> disc, low, onstack, comp;
    stack<int> st;
    int timer = 0, compCnt = 0;

    TarjanSCC(int n) : n(n), adj(n), disc(n, -1), low(n, 0), onstack(n, 0), comp(n, -1) {}

    void addEdge(int u, int v) { adj[u].push_back(v); }

    void dfs(int v) {
        disc[v] = low[v] = timer++;
        st.push(v);
        onstack[v] = 1;

        for (int u : adj[v]) {
            if (disc[u] == -1) {
                dfs(u);
                low[v] = min(low[v], low[u]);
            } else if (onstack[u]) {
            low[v] = min(low[v], disc[u]);
        }
    }

    if (low[v] == disc[v]) {
        // v is head of SCC
        while (true) {
            int u = st.top(); st.pop();
            onstack[u] = 0;
            comp[u] = compCnt;
            if (u == v) break;
        }
        compCnt++;
    }
}

pair<vector<int>,int> run() {
    for (int i = 0; i < n; ++i) if (disc[i] == -1) dfs(i);
    return {comp, compCnt};
}
};

```

Tarjan maintains `disc[]` (discovery time), `low[]` (lowest discovery reachable), a stack of active nodes, and when `low[v] == disc[v]` it pops the stack to form an SCC. The `comp` values are assigned incrementally; note that the component numbering reflects the order components are completed (which is reverse topological order of the condensation DAG).

Both algorithms run in `O(V + E)` and are stable in practice. Use Kosaraju when you prefer clarity and can afford to build the reversed graph; pick Tarjan when you want a single-pass solution or memory saving by not making the reversed adjacency list.

Code to create DAG to do this however we should have which node is being given to which component.

```cpp
vector<vector<int>> dag(compCnt);
vector<unordered_set<int>> edgeset(compCnt);  // to avoid duplicate edges

for (int v = 0; v < n; v++) {
    for (int u : adj[v]) {
        int a = comp[v], b = comp[u];
        if (a != b && !edgeset[a].count(b)) {
            dag[a].push_back(b);
            edgeset[a].insert(b);
        }
    }
}

```

## Problems and key points

Many contest and real-world problems revolve around SCCs. Typical tasks include counting SCCs, finding the size of the largest SCC, checking whether two vertices are in the same SCC (constant time after SCC labeling), finding source or sink SCCs (components with no incoming or no outgoing edges in the condensation graph), and condensing the graph to run DP on the DAG of components. Another extremely common application is the **2-SAT problem**: build an implication graph with `2n` nodes (variable and its negation), find SCCs, and check for contradictions by ensuring no variable and its negation lie in the same SCC; if they do, the formula is unsatisfiable, otherwise a consistent assignment can be recovered from the topological order of components.

A crucial practical point is robustness to recursion depth. Both Kosaraju and Tarjan normally use recursion for DFS; on graphs that form a long path of length near `n` the recursion depth can overflow. In C++ this can cause runtime failure due to stack overflow. Two remedies are increasing stack size (platform-dependent and sometimes not permitted), or converting the recursive DFS to an iterative version using an explicit stack. Gabow’s algorithm and iterative implementations of Tarjan exist and are recommended in systems where recursion is unsafe. Another practical issue is memory layout: always prefer adjacency lists (`vector<vector<int>>`) and, when you know `E` ahead of time, reserve space for adjacency vectors to avoid repeated reallocations. For very large graphs, consider compressed adjacency storage or streaming/online algorithms.

When condensing SCCs into a DAG it is common to want to compute indegree/outdegree of each component or to run DP (e.g., find longest path on DAG, count number of reachable original nodes from each component). Building the condensed graph is straightforward: for every original edge `(u->v)`, if `comp[u] != comp[v]` add an edge from `comp[u]` to `comp[v]` (usually with deduplication using a `set` or by sorting+unique, or by using a boolean marker per target to avoid duplicates if memory/time matters). Because the condensed graph is a DAG, many linear-time DP strategies apply: topological ordering provides natural processing order, and dynamic programming on DAGs solves many optimization problems that are hard on cyclic graphs.

A set of canonical pitfalls appear frequently in contest code: forgetting to clear or reinitialize auxiliary arrays between test cases, mixing 0-based and 1-based indexing, incorrect handling of self-loops (self-loop makes a single-vertex SCC nontrivial), and incorrectly assuming component ids have any particular topological order — Kosaraju and Tarjan produce different id orders by default. Also, be careful when using SCCs in problems that require path reconstruction to not lose original vertex identities: store mapping arrays `comp[v]` and the reverse mapping from `comp` to list of original vertices if needed.
## Problems:

1. Given a directed graph `G`. Find how many nodes at minimum should an infection be planted on so that All the nodes get infected in the end.

Solution: We can use SGG to collapse into one node and then collapse the entire graph into DAG. Now answer is all the nodes with indegree `0`. And that's it.
